{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBlamqU+GlseWqRdgPDOfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoLangreo7/EII-RI/blob/main/Ejercicio3_RI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ej. 3. Expansión de consultas**"
      ],
      "metadata": {
        "id": "0DIMOaNLGott"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este nuevo ejercicio, se nos pide que, utilizando la mejor configuración determinada en el segundo ejercicio, implementar un sistema de expansión de consultas empleando la técnica del signed root log likelihood ratio test."
      ],
      "metadata": {
        "id": "VwerC2A_MUEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a repetir el proceso inicial, para tener la coleccion operativa, es decir, ya indexada:\n"
      ],
      "metadata": {
        "id": "z0bbUKBda8hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos el paquete bm25s\n",
        "!pip install bm25s[full]\n",
        "\n",
        "# Importamos las librerías necesarias\n",
        "import bm25s\n",
        "import Stemmer\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Descargamos la colección y las consultas y las query\n",
        "!gdown 19pzNFYIch8rj9d3kyq-171V8vRa_wLBC\n",
        "!unzip -o trec-covid-RI.zip\n",
        "\n",
        "# Parseamos la colección\n",
        "with open(\"corpus.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus_content = []\n",
        "    for line in f:\n",
        "        corpus_content.append(json.loads(line))\n",
        "\n",
        "# Indexamos la colección\n",
        "corpus_verbatim = list()\n",
        "corpus_plaintext = list()\n",
        "for entry in corpus_content:\n",
        "  document = {\"id\": entry[\"_id\"], \"title\": entry[\"title\"].lower(),\n",
        "  \"text\": entry[\"text\"].lower()}\n",
        "  corpus_verbatim.append(document)\n",
        "  corpus_plaintext.append(entry[\"text\"].lower())"
      ],
      "metadata": {
        "id": "j8fSyetGX-_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez ya tenemos nuestra coleccion, utilizamos una funcion proporcionada por el profesor de practicas para facilitarnos la tarea. Con ella nos permite calcular las frecuencias de términos para nuestro corpus."
      ],
      "metadata": {
        "id": "ZQBVz4q_bR8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_term_frequencies_from_corpus_tokenized(corpus_tokenized):\n",
        "    from collections import Counter\n",
        "\n",
        "    tmp = dict()\n",
        "\n",
        "    for document in corpus_tokenized[0]:\n",
        "        freqs = dict(Counter(document))\n",
        "        for token, freq in freqs.items():\n",
        "            try:\n",
        "                tmp[token] += freq\n",
        "            except:\n",
        "                tmp[token] = freq\n",
        "\n",
        "    inverted_vocab = {corpus_tokenized[1][key]: key for key in corpus_tokenized[1].keys()}\n",
        "\n",
        "    total_freqs = dict()\n",
        "\n",
        "    for key, freq in dict(tmp).items():\n",
        "        term = inverted_vocab[key]\n",
        "        total_freqs[term] = freq\n",
        "\n",
        "    return total_freqs"
      ],
      "metadata": {
        "id": "d-6OTytZNaUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tengamos la coleccion inicial indexada, y la funcion declarada, dejamos ya calculados los terminos para la coleccion general:"
      ],
      "metadata": {
        "id": "n_UD_fGrLplb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_flavor = \"robertson\"\n",
        "idf_flavor = \"robertson\"\n",
        "\n",
        "initial_corpus_tokenized = bm25s.tokenize(corpus_plaintext, stopwords=None, stemmer=Stemmer.Stemmer(\"english\"))\n",
        "initial_compute_term_frequencies = compute_term_frequencies_from_corpus_tokenized(initial_corpus_tokenized)\n",
        "print(initial_compute_term_frequencies)"
      ],
      "metadata": {
        "id": "NOautHbRbsWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, dejaremos las consultas cargadas desde nuestro fichero de consultas, ademas de dejar preparado el retriever para su posterior uso."
      ],
      "metadata": {
        "id": "k-UR_AJKNBXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#queries cargadas\n",
        "queries = []\n",
        "\n",
        "with open(\"queries.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        queries.append(json.loads(line))\n",
        "\n",
        "retriever = bm25s.BM25(corpus=corpus_verbatim,method=bm25_flavor,idf_method=idf_flavor)\n",
        "retriever.index(initial_corpus_tokenized, show_progress=True)"
      ],
      "metadata": {
        "id": "2XTgUJPVNNzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para cada consulta sera necesario mediante el algoritmo de LLRs, expandirla añadiendo a cada uno los terminos mas populares contrastados con los terminos populares de la coleccion en general. Para ello creamos el metodo de expandir consultar, para que para cada query reciba su expansion y contrastar esta mejora con la respuesta run sin ella."
      ],
      "metadata": {
        "id": "7SP3meSLTotR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve el texto plano de los n documentos mas relevantes\n",
        "def get_n_valuable_documents_for_query(query, retriever, n):\n",
        "    # Convierte el texto de la consulta a minúsculas\n",
        "    query_string = query[\"text\"].lower()\n",
        "\n",
        "    # Tokeniza la consulta\n",
        "    query_tokenized = bm25s.tokenize(\n",
        "        query_string,\n",
        "        stopwords=None,\n",
        "        stemmer=Stemmer.Stemmer(\"english\"),\n",
        "        show_progress=False\n",
        "    )\n",
        "\n",
        "    # Recupera los documentos relevantes usando el índice BM25\n",
        "    results = retriever.retrieve(\n",
        "        query_tokenized,\n",
        "        corpus=retriever.corpus,\n",
        "        k=n,\n",
        "        return_as=\"tuple\",\n",
        "        show_progress=False\n",
        "    )\n",
        "\n",
        "    # Itera sobre los documentos recuperados y agrega su texto a text_content\n",
        "    text_content = \"\"\n",
        "    for document in results.documents[0]:\n",
        "        text_content += document['text'] + \" \"\n",
        "\n",
        "    return text_content\n",
        "\n",
        "\n",
        "# Devuelve los terminos con mas frecuencia para un texto plano (el de la query)\n",
        "def get_term_frequency_for_query(query_text):\n",
        "    queried_corpus_tokenized = bm25s.tokenize(query_text, stopwords=None, stemmer=Stemmer.Stemmer(\"english\"))\n",
        "    return compute_term_frequencies_from_corpus_tokenized(queried_corpus_tokenized)\n",
        "\n",
        "\n",
        "# Compara las frecuencias de los terminos de toda la coleccion, con la los archivos de la query\n",
        "def comparate_frequencies(dictA, dictB, m):\n",
        "    result = LogLikelihood.compare_frequencies(dictA, dictB, max_return=m, threshold=0)\n",
        "    return result\n",
        "\n",
        "\n",
        "# Expande la query para implementar los terminos resutantes del algoritmo explicado\n",
        "def query_expansion(query, retriever, n, m):\n",
        "    text = get_n_valuable_documents_for_query(query, retriever, n)\n",
        "    term_frequencies = get_term_frequency_for_query(text)\n",
        "    tf_terms = comparate_frequencies(initial_compute_term_frequencies, term_frequencies, m)\n",
        "\n",
        "    # Accede al atributo item de cada ScoredItem\n",
        "    tf_terms_items = [item.item for item in tf_terms]\n",
        "\n",
        "    original_terms = query[\"text\"].split()\n",
        "\n",
        "    # Extiende la consulta con los términos relevantes\n",
        "    the_extended_one = original_terms[:]\n",
        "    for term in tf_terms_items:\n",
        "        if term not in the_extended_one:\n",
        "            the_extended_one.append(term)\n",
        "\n",
        "    return the_extended_one"
      ],
      "metadata": {
        "id": "sB1le3T0SjBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular los LLR con signo, se nos proporciona un codigo de ejemplo en lenguaje java, para ello traducimos este texto a python para su uso en este programa:"
      ],
      "metadata": {
        "id": "CgLdgK9Z376d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "class LogLikelihood:\n",
        "    @staticmethod\n",
        "    def entropy(*elements):\n",
        "        total_sum = sum(elements)\n",
        "        result = sum(LogLikelihood.x_log_x(e) for e in elements)\n",
        "        return LogLikelihood.x_log_x(total_sum) - result\n",
        "\n",
        "    @staticmethod\n",
        "    def x_log_x(x):\n",
        "        return 0.0 if x == 0 else x * math.log(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def log_likelihood_ratio(k11, k12, k21, k22):\n",
        "        if any(k < 0 for k in [k11, k12, k21, k22]):\n",
        "            raise ValueError(\"Counts must be non-negative.\")\n",
        "\n",
        "        row_entropy = LogLikelihood.entropy(k11 + k12, k21 + k22)\n",
        "        column_entropy = LogLikelihood.entropy(k11 + k21, k12 + k22)\n",
        "        matrix_entropy = LogLikelihood.entropy(k11, k12, k21, k22)\n",
        "\n",
        "        if row_entropy + column_entropy < matrix_entropy:\n",
        "            return 0.0\n",
        "\n",
        "        return 2.0 * (row_entropy + column_entropy - matrix_entropy)\n",
        "\n",
        "    @staticmethod\n",
        "    def root_log_likelihood_ratio(k11, k12, k21, k22):\n",
        "        llr = LogLikelihood.log_likelihood_ratio(k11, k12, k21, k22)\n",
        "        sqrt_llr = math.sqrt(llr)\n",
        "        if k11 / (k11 + k12) < k21 / (k21 + k22):\n",
        "            sqrt_llr = -sqrt_llr\n",
        "        return sqrt_llr\n",
        "\n",
        "    @staticmethod\n",
        "    def compare_frequencies(a, b, max_return, threshold):\n",
        "        total_a = sum(a.values())\n",
        "        total_b = sum(b.values())\n",
        "\n",
        "        best = []\n",
        "\n",
        "        for item in a:\n",
        "            LogLikelihood._compare_and_add(a, b, max_return, threshold, total_a, total_b, best, item)\n",
        "\n",
        "        if threshold < 0:\n",
        "            for item in b:\n",
        "                if item not in a:\n",
        "                    LogLikelihood._compare_and_add(a, b, max_return, threshold, total_a, total_b, best, item)\n",
        "\n",
        "        return sorted(best, key=lambda x: -x.score)\n",
        "\n",
        "    @staticmethod\n",
        "    def _compare_and_add(a, b, max_return, threshold, total_a, total_b, best, item):\n",
        "        k_a = a.get(item, 0)\n",
        "        k_b = b.get(item, 0)\n",
        "        score = LogLikelihood.root_log_likelihood_ratio(k_a, total_a - k_a, k_b, total_b - k_b)\n",
        "\n",
        "        if score >= threshold:\n",
        "            heappush(best, ScoredItem(item, score))\n",
        "            if len(best) > max_return:\n",
        "                heappop(best)\n",
        "\n",
        "class ScoredItem:\n",
        "    def __init__(self, item, score):\n",
        "        self.item = item\n",
        "        self.score = score\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.score < other.score"
      ],
      "metadata": {
        "id": "L6ZvvWGq3VX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo todo lo anterior, podremos expandir nuestras queries:"
      ],
      "metadata": {
        "id": "gcwKUrKB-vZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expande la lista de queries para unos parametros dados\n",
        "def get_expanded_queries(queries, retriever, n, m):\n",
        "    expanded_queries = []\n",
        "    for query in queries:\n",
        "        expanded_query = query_expansion(query, retriever, n, m)\n",
        "        expanded_queries.append({\n",
        "            \"_id\": query[\"_id\"],\n",
        "            \"text\": \" \".join(expanded_query)\n",
        "        })\n",
        "    return expanded_queries"
      ],
      "metadata": {
        "id": "sMPvrhx6EhUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos las consultas ampliadas, haremos un run con el metodo ya usado en el ejercicio anterior con el fin de volver a enviar al índice BM25S para obtener la lista definitiva de resultados, luego usaremos estos resultados para compararlos con el resultado sin las query expandidas, con otra vez, un metodo del anterior ejercicio."
      ],
      "metadata": {
        "id": "skukJmR_AVvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_queries_and_get_run(queries, retriever, max_results=100):\n",
        "    # Inicializa un diccionario para almacenar los resultados de cada consulta\n",
        "    run = {}\n",
        "\n",
        "    # Itera sobre cada consulta en la lista de consultas\n",
        "    for query in queries:\n",
        "        # Obtiene el ID único de la consulta\n",
        "        query_id = query[\"_id\"]\n",
        "\n",
        "        # Convierte el texto de la consulta a minúsculas\n",
        "        query_string = query[\"text\"].lower()\n",
        "\n",
        "        # Tokeniza la consulta utilizando las stopwords y el stemmer proporcionados\n",
        "        query_tokenized = bm25s.tokenize(\n",
        "            query_string,\n",
        "            stopwords=None,\n",
        "            stemmer=Stemmer.Stemmer(\"english\"),\n",
        "            show_progress=False\n",
        "        )\n",
        "\n",
        "        # Recupera los documentos relevantes usando el índice BM25\n",
        "        results = retriever.retrieve(\n",
        "            query_tokenized,\n",
        "            corpus=retriever.corpus,\n",
        "            k=max_results,\n",
        "            return_as=\"tuple\",\n",
        "            show_progress=False\n",
        "        )\n",
        "\n",
        "        # Obtiene los documentos recuperados y sus scores de relevancia\n",
        "        returned_documents = results.documents[0]\n",
        "\n",
        "        # Inicializa una lista para almacenar los IDs de los documentos recuperados\n",
        "        returned_ids = []\n",
        "        for i in range(len(returned_documents)):\n",
        "            # Agrega el ID de cada documento recuperado a la lista\n",
        "            returned_ids.append(str(returned_documents[i][\"id\"]))\n",
        "\n",
        "        # Asocia la lista de IDs recuperados con el ID de la consulta en el diccionario\n",
        "        run[query_id] = returned_ids\n",
        "\n",
        "    # Devuelve el diccionario con los resultados de todas las consultas\n",
        "    return run\n",
        "\n",
        "\n",
        "# Función adaptada para calcular precision, recall y F1\n",
        "\n",
        "def compute_precision_recall_f1(run, relevance_judgements):\n",
        "    precision_values = []\n",
        "    recall_values = []\n",
        "    f1_values = []\n",
        "\n",
        "    global_retrieved = 0\n",
        "    global_relevant = 0\n",
        "    global_retrieved_and_relevant = 0\n",
        "\n",
        "    for query_id in run.keys():\n",
        "        retrieved_results = run[query_id]\n",
        "        relevant_results = relevance_judgements.get(query_id, [])\n",
        "        relevant_and_retrieved = set(retrieved_results) & set(relevant_results)\n",
        "\n",
        "        global_retrieved += len(retrieved_results)\n",
        "        global_relevant += len(relevant_results)\n",
        "        global_retrieved_and_relevant += len(relevant_and_retrieved)\n",
        "\n",
        "        precision = len(relevant_and_retrieved) / len(retrieved_results) if len(retrieved_results) > 0 else 0\n",
        "        recall = len(relevant_and_retrieved) / len(relevant_results) if len(relevant_results) > 0 else 0\n",
        "\n",
        "        if (precision + recall) > 0:\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "            f1_values.append(f1)\n",
        "\n",
        "        precision_values.append(precision)\n",
        "        recall_values.append(recall)\n",
        "\n",
        "    macro_average_precision = sum(precision_values) / len(precision_values) if precision_values else 0\n",
        "    macro_average_recall = sum(recall_values) / len(recall_values) if recall_values else 0\n",
        "    macro_average_f1 = sum(f1_values) / len(f1_values) if f1_values else 0\n",
        "\n",
        "    micro_average_precision = global_retrieved_and_relevant / global_retrieved if global_retrieved > 0 else 0\n",
        "    micro_average_recall = global_retrieved_and_relevant / global_relevant if global_relevant > 0 else 0\n",
        "    micro_average_f1 = (2 * (micro_average_precision * micro_average_recall) /\n",
        "                        (micro_average_precision + micro_average_recall)) if (micro_average_precision + micro_average_recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"macro_precision\": macro_average_precision,\n",
        "        \"macro_recall\": macro_average_recall,\n",
        "        \"macro_f1\": macro_average_f1,\n",
        "        \"micro_precision\": micro_average_precision,\n",
        "        \"micro_recall\": micro_average_recall,\n",
        "        \"micro_f1\": micro_average_f1\n",
        "    }\n",
        "\n",
        "\n",
        "# Cargar juicios de relevancia desde qrels.tsv\n",
        "relevance_judgements = {}\n",
        "with open(\"qrels.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    next(f)  # Saltar la cabecera\n",
        "    for line in f:\n",
        "        query_id, corpus_id, score = line.strip().split(\"\\t\")\n",
        "        if int(score) > 0:  # Considerar solo documentos relevantes (score > 0)\n",
        "            if query_id not in relevance_judgements:\n",
        "                relevance_judgements[query_id] = []\n",
        "            relevance_judgements[query_id].append(corpus_id)\n"
      ],
      "metadata": {
        "id": "BF-niH8cbgpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora por cada conjunto de queries, obtenemos el run y comparamos\n",
        "\n"
      ],
      "metadata": {
        "id": "lm2DAX1bDFg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_original = submit_queries_and_get_run(queries, retriever, max_results=100)\n",
        "\n",
        "metrics = compute_precision_recall_f1(run_original, relevance_judgements)\n",
        "print(\"Resultados obtenidos de la ejecucion sin las consultas expandidas:\\n\")\n",
        "print(f\"Macro-averaged Precision: {metrics['macro_precision']:.3f}\")\n",
        "print(f\"Macro-averaged Recall: {metrics['macro_recall']:.3f}\")\n",
        "print(f\"Macro-averaged F1: {metrics['macro_f1']:.3f}\\n\")\n",
        "print(f\"Micro-averaged Precision: {metrics['micro_precision']:.3f}\")\n",
        "print(f\"Micro-averaged Recall: {metrics['micro_recall']:.3f}\")\n",
        "print(f\"Micro-averaged F1: {metrics['micro_f1']:.3f}\\n\")\n",
        "\n",
        "expanded_queries = get_expanded_queries(queries, retriever, 100, 5)\n",
        "run_original = submit_queries_and_get_run(expanded_queries, retriever, max_results=100)\n",
        "\n",
        "metrics = compute_precision_recall_f1(run_original, relevance_judgements)\n",
        "print(\"Resultados obtenidos de la ejecucion con las consultas expandidas:\\n\")\n",
        "print(f\"Macro-averaged Precision: {metrics['macro_precision']:.3f}\")\n",
        "print(f\"Macro-averaged Recall: {metrics['macro_recall']:.3f}\")\n",
        "print(f\"Macro-averaged F1: {metrics['macro_f1']:.3f}\\n\")\n",
        "print(f\"Micro-averaged Precision: {metrics['micro_precision']:.3f}\")\n",
        "print(f\"Micro-averaged Recall: {metrics['micro_recall']:.3f}\")\n",
        "print(f\"Micro-averaged F1: {metrics['micro_f1']:.3f}\\n\")\n"
      ],
      "metadata": {
        "id": "4rvKX6PAe21w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui podemos contrastar resultados, en donde dependiendo del n y el m es mas rentable la expansion o no."
      ],
      "metadata": {
        "id": "ct-tnjQmGHI_"
      }
    }
  ]
}