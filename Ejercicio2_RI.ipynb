{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTu9vBjIJp3lo9jL9pztDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoLangreo7/EII-RI/blob/main/Ejercicio2_RI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ej. 2. Experimentación con variantes de BM25\n"
      ],
      "metadata": {
        "id": "A1MHyt-o2naj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este segundo ejercicio, se nos pide desarrollar un código que genere “rondas” de resultados con 100 documentos (solo los identificadores) para todas las consultas de la colección. Dichas rondas deben ejecutarse considerando todas las combinaciones posibles de parámetros."
      ],
      "metadata": {
        "id": "Z2XwyIdl2pH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos preparando los archivos necesarios, como hicimos en el ejercicio anterior:"
      ],
      "metadata": {
        "id": "AOZXVjOs3-mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#descargamos paquete bm25s\n",
        "!pip install bm25s[full]\n",
        "#descargamos las librerias que usaremos\n",
        "import bm25s\n",
        "import Stemmer\n",
        "import json\n",
        "#descargamos la coleccion y las query\n",
        "!gdown 19pzNFYIch8rj9d3kyq-171V8vRa_wLBC\n",
        "!unzip -o trec-covid-RI.zip\n",
        "#parseamos la coleccion\n",
        "with open(\"corpus.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus_content = []\n",
        "    for line in f:\n",
        "        corpus_content.append(json.loads(line))\n",
        "#indexamos la coleccion\n",
        "corpus_verbatim = list()\n",
        "corpus_plaintext = list()\n",
        "for entry in corpus_content:\n",
        "  document = {\"id\": entry[\"_id\"], \"title\": entry[\"title\"].lower(),\n",
        "  \"text\": entry[\"text\"].lower()}\n",
        "  corpus_verbatim.append(document)\n",
        "  corpus_plaintext.append(entry[\"text\"].lower())"
      ],
      "metadata": {
        "id": "NcTALLOz9z78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya tenemos la coleccion preparada para la realización del ejercicio."
      ],
      "metadata": {
        "id": "ik8nCbsxA3j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, usaremos este método extraido de las prácticas de laboratorio, que nos permitirá enviar las consultas y obtener los resultados asociados a ellas, para\n",
        "posteriormente calcular el rendimiento:\n"
      ],
      "metadata": {
        "id": "0L05_382GEFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_queries_and_get_run(queries, stemmer, retriever, stopwords, max_results=100):\n",
        "    # Inicializa un diccionario para almacenar los resultados de cada consulta\n",
        "    run = {}\n",
        "\n",
        "    # Itera sobre cada consulta en la lista de consultas\n",
        "    for query in queries:\n",
        "        # Obtiene el ID único de la consulta\n",
        "        query_id = query[\"_id\"]\n",
        "\n",
        "        # Convierte el texto de la consulta a minúsculas\n",
        "        query_string = query[\"text\"].lower()\n",
        "\n",
        "        # Tokeniza la consulta utilizando las stopwords y el stemmer proporcionados\n",
        "        query_tokenized = bm25s.tokenize(\n",
        "            query_string,\n",
        "            stopwords=stopwords,\n",
        "            stemmer=stemmer,\n",
        "            show_progress=False\n",
        "        )\n",
        "\n",
        "        # Recupera los documentos relevantes usando el índice BM25\n",
        "        results = retriever.retrieve(\n",
        "            query_tokenized,\n",
        "            corpus=retriever.corpus,\n",
        "            k=max_results,\n",
        "            return_as=\"tuple\",\n",
        "            show_progress=False\n",
        "        )\n",
        "\n",
        "        # Obtiene los documentos recuperados y sus scores de relevancia\n",
        "        returned_documents = results.documents[0]\n",
        "\n",
        "        # Inicializa una lista para almacenar los IDs de los documentos recuperados\n",
        "        returned_ids = []\n",
        "        for i in range(len(returned_documents)):\n",
        "            # Agrega el ID de cada documento recuperado a la lista\n",
        "            returned_ids.append(str(returned_documents[i][\"id\"]))\n",
        "\n",
        "        # Asocia la lista de IDs recuperados con el ID de la consulta en el diccionario\n",
        "        run[query_id] = returned_ids\n",
        "\n",
        "    # Devuelve el diccionario con los resultados de todas las consultas\n",
        "    return run\n"
      ],
      "metadata": {
        "id": "-X3Ke015HRjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparamos las querys que vamos a utilizar con este otro metodo, tambien extraido de las practicas de laboratorio:"
      ],
      "metadata": {
        "id": "um4_pGQkrZC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = []\n",
        "\n",
        "with open(\"queries.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        queries.append(json.loads(line))"
      ],
      "metadata": {
        "id": "hznfAMflreik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un metodo para poder descargar los archivos en disco, donde apareceran las metricas y el restulado de la run correspondiente:"
      ],
      "metadata": {
        "id": "9jler4I0onuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_run_to_disk(run, bm25_flavor, stopwords, stemming, metrics, max_results=100):\n",
        "    stopwords_str = \"Stopwords\" if stopwords else \"NON-stopwords\"\n",
        "    stemming_str = \"Stemming\" if stemming else \"NON-stemming\"\n",
        "\n",
        "    filename = f\"{bm25_flavor}-{stopwords_str}-{stemming_str}.json\"\n",
        "\n",
        "    # Crear una estructura que combine los resultados del run y las métricas\n",
        "    run_data = {\n",
        "        \"bm25_flavor\": bm25_flavor,\n",
        "        \"stopwords\": stopwords_str,\n",
        "        \"stemming\": stemming_str,\n",
        "        \"max_results\": max_results,\n",
        "        \"metrics\": {\n",
        "            \"macro_precision\": metrics[\"macro_precision\"],\n",
        "            \"macro_recall\": metrics[\"macro_recall\"],\n",
        "            \"macro_f1\": metrics[\"macro_f1\"],\n",
        "            \"micro_precision\": metrics[\"micro_precision\"],\n",
        "            \"micro_recall\": metrics[\"micro_recall\"],\n",
        "            \"micro_f1\": metrics[\"micro_f1\"]\n",
        "        },\n",
        "        \"run\": run\n",
        "    }\n",
        "\n",
        "    # Guardar los datos combinados en un archivo JSON\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(run_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "uWjujBtHnoq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que ya tenemos la coleccion indexada, las queries y el metodo para ir experimentando, preparamos el stemmer, tokenizamos para cada caso, e indexandolo antes de llamar a la funcion \"submit_queries_and_get_run\" que realizara la busqueda. Luego estos resultados se guardaran en disco para aportar a la entrega, y en un array para su posterior uso.\n"
      ],
      "metadata": {
        "id": "IWcZEhNbtw0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemmer para cuando queramos usarlo (cuando no, ponemos directamente NONE)\n",
        "stemmer = Stemmer.Stemmer(\"english\")\n",
        "\n",
        "# Lista para almacenar las diferentes configuraciones de ejecuciones\n",
        "runs = []\n",
        "\n",
        "# Iterar por todas las configuraciones\n",
        "for bm25_config in [\"lucene\", \"robertson\", \"atire\", \"bm25+\", \"bm25l\"]:\n",
        "    for stopwords_config in [None, \"en\"]:  # None es sin stopwords, \"en\" es con stopwords\n",
        "        for stemming_config in [None, stemmer]:  # None es sin stemming, stemmer es con stemming\n",
        "            # Configurar BM25\n",
        "            bm25_flavor = bm25_config\n",
        "            idf_flavor = bm25_config\n",
        "\n",
        "            # Tokenizar colección\n",
        "            corpus_tokenized = bm25s.tokenize(corpus_plaintext,stopwords=stopwords_config,\n",
        "                                              stemmer=stemming_config,show_progress=True)\n",
        "\n",
        "            # Indexar colección tokenizada\n",
        "            retriever = bm25s.BM25(corpus=corpus_verbatim,method=bm25_flavor,\n",
        "                idf_method=idf_flavor)\n",
        "            retriever.index(corpus_tokenized, show_progress=True)\n",
        "\n",
        "            # Ejecutar consultas y obtener resultados\n",
        "            run = submit_queries_and_get_run(queries, stemming_config, retriever, stopwords_config, max_results=100)\n",
        "\n",
        "            # Almacenar resultados para uso posterior\n",
        "            runs.append(run)"
      ],
      "metadata": {
        "id": "FrV3qO9qt7cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos almacenados las colecciones indexadas de las distintas formas (en total 20), vamos a proceder a las rondas de busqueda. Para ello vamos a hacer uso del método  y de las queries antes cargadas:"
      ],
      "metadata": {
        "id": "XUGyTFeMzspP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función adaptada para calcular precision, recall y F1\n",
        "\n",
        "def compute_precision_recall_f1(run, relevance_judgements):\n",
        "    precision_values = []\n",
        "    recall_values = []\n",
        "    f1_values = []\n",
        "\n",
        "    global_retrieved = 0\n",
        "    global_relevant = 0\n",
        "    global_retrieved_and_relevant = 0\n",
        "\n",
        "    for query_id in run.keys():\n",
        "        retrieved_results = run[query_id]\n",
        "        relevant_results = relevance_judgements.get(query_id, [])\n",
        "        relevant_and_retrieved = set(retrieved_results) & set(relevant_results)\n",
        "\n",
        "        global_retrieved += len(retrieved_results)\n",
        "        global_relevant += len(relevant_results)\n",
        "        global_retrieved_and_relevant += len(relevant_and_retrieved)\n",
        "\n",
        "        precision = len(relevant_and_retrieved) / len(retrieved_results) if len(retrieved_results) > 0 else 0\n",
        "        recall = len(relevant_and_retrieved) / len(relevant_results) if len(relevant_results) > 0 else 0\n",
        "\n",
        "        if (precision + recall) > 0:\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "            f1_values.append(f1)\n",
        "\n",
        "        precision_values.append(precision)\n",
        "        recall_values.append(recall)\n",
        "\n",
        "    macro_average_precision = sum(precision_values) / len(precision_values) if precision_values else 0\n",
        "    macro_average_recall = sum(recall_values) / len(recall_values) if recall_values else 0\n",
        "    macro_average_f1 = sum(f1_values) / len(f1_values) if f1_values else 0\n",
        "\n",
        "    micro_average_precision = global_retrieved_and_relevant / global_retrieved if global_retrieved > 0 else 0\n",
        "    micro_average_recall = global_retrieved_and_relevant / global_relevant if global_relevant > 0 else 0\n",
        "    micro_average_f1 = (2 * (micro_average_precision * micro_average_recall) /\n",
        "                        (micro_average_precision + micro_average_recall)) if (micro_average_precision + micro_average_recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"macro_precision\": macro_average_precision,\n",
        "        \"macro_recall\": macro_average_recall,\n",
        "        \"macro_f1\": macro_average_f1,\n",
        "        \"micro_precision\": micro_average_precision,\n",
        "        \"micro_recall\": micro_average_recall,\n",
        "        \"micro_f1\": micro_average_f1\n",
        "    }\n",
        "\n",
        "# Cargar juicios de relevancia desde qrels.tsv\n",
        "relevance_judgements = {}\n",
        "with open(\"qrels.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    next(f)  # Saltar la cabecera\n",
        "    for line in f:\n",
        "        query_id, corpus_id, score = line.strip().split(\"\\t\")\n",
        "        if int(score) > 0:  # Considerar solo documentos relevantes (score > 0)\n",
        "            if query_id not in relevance_judgements:\n",
        "                relevance_judgements[query_id] = []\n",
        "            relevance_judgements[query_id].append(corpus_id)\n",
        "\n",
        "# Esto es con el fin de identificar cada resultado\n",
        "bm25_configs = [\"lucene\", \"robertson\", \"atire\", \"bm25+\", \"bm25l\"]\n",
        "stopwords_configs = [None, \"en\"]\n",
        "stemming_configs = [None, Stemmer.Stemmer(\"english\")]\n",
        "config_index = 0\n",
        "# Ahora si lo calculamos\n",
        "for bm25_config in bm25_configs:\n",
        "    for stopwords_config in stopwords_configs:\n",
        "        for stemming_config in stemming_configs:\n",
        "            print(f\"Evaluando configuración {config_index + 1}: BM25={bm25_config}, Stopwords={'Yes' if stopwords_config else 'No'}, Stemming={'Yes' if stemming_config else 'No'}\")\n",
        "            metrics = compute_precision_recall_f1(runs[config_index], relevance_judgements)\n",
        "            print(f\"Macro-averaged Precision: {metrics['macro_precision']:.3f}\")\n",
        "            print(f\"Macro-averaged Recall: {metrics['macro_recall']:.3f}\")\n",
        "            print(f\"Macro-averaged F1: {metrics['macro_f1']:.3f}\\n\")\n",
        "            print(f\"Micro-averaged Precision: {metrics['micro_precision']:.3f}\")\n",
        "            print(f\"Micro-averaged Recall: {metrics['micro_recall']:.3f}\")\n",
        "            print(f\"Micro-averaged F1: {metrics['micro_f1']:.3f}\\n\")\n",
        "\n",
        "            # Guardar el run y las métricas asociadas en disco\n",
        "            save_run_to_disk(\n",
        "                 run=runs[config_index],\n",
        "                 bm25_flavor=bm25_config,\n",
        "                 stopwords=stopwords_config,\n",
        "                 stemming=stemming_config,\n",
        "                 metrics=metrics\n",
        "            )\n",
        "\n",
        "            config_index += 1"
      ],
      "metadata": {
        "id": "OPiJ8mLx0E9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En base a los resultados obtenidos, el mejor promediado es la configuracion 19, es decir, BM25=robertson / Stopwords=No / Stemming=Yes\n"
      ],
      "metadata": {
        "id": "TVF3WCVDefrf"
      }
    }
  ]
}